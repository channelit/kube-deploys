apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    run: kafka2
  name: kafka2
  namespace: kafka
spec:
  replicas: 1
  selector:
    matchLabels:
      run: kafka2
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      name: kafka2
      labels:
        run: kafka2
    spec:
      containers:
        - image: ghcr.io/channelit/kafka:latest
          imagePullPolicy: Always
          name: kafka2
          command: ["/bin/sh", "-c"]
          # args: ["export KAFKA_CLUSTER_ID=\"$(/opt/kafka/bin/kafka-storage.sh random-uuid)\"; /opt/kafka/bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c /conf/server.properties; /opt/kafka/bin/kafka-server-start.sh /conf/server.properties"]
          # args: ["/opt/kafka/bin/kafka-storage.sh format --ignore-formatted -t $(/opt/kafka/bin/kafka-storage.sh random-uuid) -c /conf/server.properties; /opt/kafka/bin/kafka-server-start.sh /conf/server.properties"]
          args: ["/opt/kafka/bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c /conf/server.properties; /opt/kafka/bin/kafka-server-start.sh /conf/server.properties"]
          resources:
            requests:
              memory: "512M"
              cpu: "500m"
            limits:
              memory: "512M"
              cpu: "500m"
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          env:
            - name: JMX_PORT
              value: "9998"
            - name: KAFKA_CLUSTER_ID
              value: o8hZC38eROOUpiucL9DbTA
            - name: KAFKA_OPTS
              value: -Djava.security.auth.login.config=/conf/jaas.config
          ports:
            - name: server1
              containerPort: 29091
              protocol: TCP
            - name: server2
              containerPort: 29092
              protocol: TCP
            - name: server3
              containerPort: 29093
              protocol: TCP
            - name: client1
              containerPort: 9091
              protocol: TCP
            - name: client2
              containerPort: 9092
              protocol: TCP
            - name: client3
              containerPort: 9093
              protocol: TCP
            - name: client-outside
              containerPort: 30092
              protocol: TCP
          volumeMounts:
            - name: kafka2-volume
              mountPath: /conf
              readOnly: true
            # - name: kafka2-logs
            #   mountPath: /kafka-logs
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
      volumes:
        - name: kafka2-volume
          configMap:
            name: kafka2-config
            items:
              - key: "server.properties"
                path: "server.properties"
              - key: "jaas.config"
                path: "jaas.config"
        # - name: kafka2-logs
        #   persistentVolumeClaim:
        #     claimName: kafka2
---
apiVersion: v1
kind: Service
metadata:
  labels:
    run: kafka2
  name: kafka2
  namespace: kafka
spec:
  ports:
    - name: broker
      port: 9092
      protocol: TCP
      targetPort: 9092
    - name: controller
      port: 29092
      protocol: TCP
      targetPort: 29092
    - name: external
      port: 39092
      protocol: TCP
      targetPort: 39092
  selector:
    run: kafka2
  type: LoadBalancer
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka2-config
  namespace: kafka
data:
  server.properties: |
      node.id=2
      process.roles=broker,controller
      controller.quorum.voters=1@kafka1:29091,2@0localhost:29092,3@kafka3:29093
      listeners=SASL_SSL://0.0.0.0:9092,CONTROLLER://0.0.0.0:29092,EXTERNAL://0.0.0.0:39092
      listener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL,EXTERNAL:PLAINTEXT
      advertised.listeners=SASL_SSL://kafka2:9092,CONTROLLER://kafka2:29092,EXTERNAL://localhost:39092
      listener.name.sasl_ssl.scram-sha-256.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
          username="admin" \
          password="admin-secret";
      listener.name.sasl_ssl.plain.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
          username="admin" \
          password="admin-secret" \
          user_admin="admin-secret" \
          user_alice="alice-secret";
      security.inter.broker.protocol=SASL_SSL
      sasl.mechanism.inter.broker.protocol=PLAIN
      sasl.enabled.mechanisms=PLAIN
      ssl.endpoint.identification.algorithm=
      num.network.threads=3
      num.io.threads=8
      controller.listener.names=CONTROLLER
      socket.send.buffer.bytes=10240
      socket.receive.buffer.bytes=102400
      socket.request.max.bytes=104857600
      num.partitions=1
      offsets.topic.replication.factor=1
      num.recovery.threads.per.data.dir=1
      transaction.state.log.replication.factor=1
      transaction.state.log.min.isr=1
      log.retention.hours=168
      log.segment.bytes=1073741824
      log.retention.check.interval.ms=300000
  jaas.config: |
      KafkaServer {
        org.apache.kafka.common.security.scram.ScramLoginModule required
        username="admin"
        password="admin-secret"
        serviceName="kafka";
      };
# ---
# apiVersion: v1
# kind: PersistentVolume
# metadata:
#   name: kafka2
#   labels:
#     run: kafka2
#   namespace: kafka
# spec:
#   storageClassName: hostpath
#   capacity:
#     storage: 512Mi
#   accessModes:
#     - ReadWriteOnce
#   hostPath:
#     path: "/Users/hardikpatel/workbench/projects/kube-deploys/kafka/data/kafka2"
# ---
# apiVersion: v1
# kind: PersistentVolumeClaim
# metadata:
#   name: kafka2
#   namespace: kafka
# spec:
#   storageClassName: hostpath
#   accessModes:
#     - ReadWriteOnce
#   resources:
#     requests:
#       storage: 512Mi